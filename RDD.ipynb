{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1f35118-f3ba-4bc9-8a2f-dc149313c343",
   "metadata": {},
   "source": [
    "- Immutable - Transformations create new RDDs\n",
    "- Distributed - Data partitioned and processed in parallel\n",
    "- Resiliten - Lineage tracks transformations for fault tolerance\n",
    "- Laziliy Evaluated - Execution plan optimized,transformations evaluated when necessary\n",
    "- Fault-tolerant operations - map,reduce,filter,collect,count,save etc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12730ea3-f444-456b-8ba0-a77e2eefc938",
   "metadata": {},
   "source": [
    "## Transformations\n",
    "- Create new RDDs by applying compution//manipulation\n",
    "- Lazy evaluation,lineage graph is created for each transformation\n",
    "- Examples -map,reduce,flatMap,reduceByKey,sortBy,join\n",
    "\n",
    "## Actions\n",
    "\n",
    "- Return results or perform actions on RDD, triggering execution\n",
    "- Eager evaluation,data movement/computation is instant\n",
    "- Examples :  collect,count,first,take,save,foreach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28b235c8-8735-4104-823d-d100d3ca23be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"SPARK_HOME\"]=\"F:\\Spark_root\\Spark\"\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"]=\"jupyter\"\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON_OPTS\"]=\"lab\"\n",
    "os.environ[\"PYSPARK_PYTHON\"]='python'\n",
    "\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c75127f-c2d0-4084-9eb6-e8476451adfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"RDD-Demo\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31b222a-97ac-4100-8a24-d5d4bbdf06f5",
   "metadata": {},
   "source": [
    "### Create Rdds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "948626f4-10fe-4eba-99b9-5e8542925630",
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = [1,2,3,4,5]\n",
    "rdd = spark.sparkContext.parallelize(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a106bbfe-1e3c-4346-800e-30bfc03afa81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# collect - Retrieves all elements of the RDD\n",
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a79f8a-7298-4c66-bb30-6130b31f957b",
   "metadata": {},
   "source": [
    "## RDDs Operations: Actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "300c23f7-85b9-4415-80f4-ecfbc644e12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "count = rdd.count()\n",
    "print(count) ## Counts number of elements in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7a3d830-bf62-4a21-9b11-5e5b9cf03dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_element = rdd.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4274efc-8bfa-4963-919b-e5e33b0f4382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(first_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88def22b-0f0f-485f-9a5c-921f69329cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thr first two elements of the rdd: [1, 2]\n"
     ]
    }
   ],
   "source": [
    "taken_elemets = rdd.take(2)\n",
    "print(\"thr first two elements of the rdd:\" , taken_elemets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "585bc54b-1624-4608-8da3-b4b66928066c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd.foreach(lambda x: print(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f015588-1bd3-49ac-9472-89a1d52f234a",
   "metadata": {},
   "source": [
    "## RDDs : transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "badf9acc-cc7b-42d9-9f3c-ff8ea1e12115",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple_data = [(\"One\",1),(\"Two\",2),(\"Three\",3),(\"Four\",4)]\n",
    "rdd=spark.sparkContext.parallelize(tuple_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbe5d62b-4a22-4cfc-879c-d68affe886c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_rdd =rdd.map(lambda x:(x[0].upper(),x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "244c5879-f955-4922-bd39-b7dcdd7634ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdd with uppercase name:  [('ONE', 1), ('TWO', 2), ('THREE', 3), ('FOUR', 4)]\n"
     ]
    }
   ],
   "source": [
    "result = mapped_rdd.collect()\n",
    "print(\"rdd with uppercase name: \",result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db419c3-bc51-4fd1-b10c-03903d4fc084",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
